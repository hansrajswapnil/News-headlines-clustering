{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Moeller's student-run newspaper, The Crusader,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>In 2008, The Crusader won First Place, the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Squire is a student literary journal that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Paul Keels - play-by-play announcer for Ohio S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Joe Uecker - Ohio State Senator (R-66) .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46112</td>\n",
       "      <td>Vancouver's characteristic approach to urban p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46113</td>\n",
       "      <td>Vancouver is also considered to have the worst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46114</td>\n",
       "      <td>The Vancouver Art Gallery is housed downtown i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46115</td>\n",
       "      <td>A prominent addition to the city's landscape i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46116</td>\n",
       "      <td>A collection of Edwardian buildings in the cit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46117 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               SENTENCES\n",
       "0      Moeller's student-run newspaper, The Crusader,...\n",
       "1      In 2008, The Crusader won First Place, the sec...\n",
       "2      The Squire is a student literary journal that ...\n",
       "3      Paul Keels - play-by-play announcer for Ohio S...\n",
       "4               Joe Uecker - Ohio State Senator (R-66) .\n",
       "...                                                  ...\n",
       "46112  Vancouver's characteristic approach to urban p...\n",
       "46113  Vancouver is also considered to have the worst...\n",
       "46114  The Vancouver Art Gallery is housed downtown i...\n",
       "46115  A prominent addition to the city's landscape i...\n",
       "46116  A collection of Edwardian buildings in the cit...\n",
       "\n",
       "[46117 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'news_headlines.xlsx')\n",
    "headlines = pd.DataFrame(df, columns=['SENTENCES'])\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whom', \"you'd\", 'himself', 'further', 'at', 'they', 'over', 'hadn', 's', \"couldn't\", 'from', 'most', 'or', 'then', 'aren', 'here', 'more', 'in', 'we', \"wouldn't\", 'during', 'haven', 'ma', 'd', 'under', 'up', 'when', 'll', 'is', 'itself', 'won', \"mustn't\", 'off', 'before', 'mightn', 'herself', 'being', \"wasn't\", 'both', 'ours', 'shouldn', 'a', \"shan't\", 'just', 'if', 'other', 'ourselves', 'he', 'so', 'm', 'into', 'an', 'have', 'doesn', 'your', 'no', 'been', 'now', 'above', 'o', 'about', 'as', 'because', 'how', 'each', 'hasn', 'against', 'couldn', 'our', 'until', \"didn't\", \"hasn't\", 'you', 'very', \"you've\", 'while', \"doesn't\", 'not', 'yourself', 'did', 'myself', 'does', 'those', 'will', \"that'll\", 'don', 'of', 'there', 'which', 'were', 'nor', 'wouldn', 'yourselves', 'needn', 'me', 'theirs', 'should', 'mustn', 'too', 'y', 'him', 'same', \"weren't\", \"it's\", 'had', 'the', 'ain', 'i', 'them', 'why', 'my', \"shouldn't\", 'down', 'and', 'wasn', 'any', 'between', 'below', 'it', 'their', 'after', 'by', 'only', 'than', 'she', 'through', \"haven't\", 'her', 'hers', 'do', 'weren', \"hadn't\", 'was', 'on', \"won't\", 'having', \"you're\", 'be', 'some', 't', 'themselves', 'has', 'am', \"aren't\", 'his', \"should've\", 'all', 'to', 'isn', 'this', 'what', 're', 'its', \"isn't\", 'who', 'can', \"needn't\", 'with', 'such', 'where', 've', 'that', 'own', \"you'll\", \"she's\", 'doing', 'out', 'but', 'for', 'are', 'yours', \"don't\", 'once', 'few', 'didn', 'shan', 'again', \"mightn't\", 'these'}\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stop_words):\n",
    "    filtered_sentence = [word for word in text if not word in stop_words] \n",
    "    filtered_sentence = [w for w in filtered_sentence if w.isalpha()]\n",
    "    return filtered_sentence                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x7f2afbcc4f60>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FT_gensim(size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_embeddings(model, text):\n",
    "    for word in text:\n",
    "        print(word)\n",
    "        print(model[word])      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['consistently', 'recognized', 'one', 'top']\\n\"\n",
      "'consistently'\n",
      "array([ 0.06896299,  0.00084916, -0.41186506,  0.3390807 ,  0.42340684,\n",
      "       -0.22432478, -0.1343737 , -0.0313811 ,  0.30376384,  0.24023326,\n",
      "       -0.45000187, -0.01167332, -0.47803038,  0.28985068,  0.19573116,\n",
      "       -0.04173116, -0.13884835,  0.13370855,  0.16825859, -0.26371962,\n",
      "       -0.16987526,  0.19343254, -0.26694676,  0.01996727, -0.582418  ,\n",
      "        0.5162271 ,  0.08524587,  0.12641689,  0.29089105,  0.0086833 ,\n",
      "       -0.4546229 ,  0.16486877,  0.05559699, -0.33825773,  0.3326733 ,\n",
      "        0.07447121, -0.11326211, -0.04724548,  0.295606  ,  0.14888783,\n",
      "       -0.00424602, -0.0485344 ,  0.2750855 , -0.04093201,  0.08931144,\n",
      "        0.13050343, -0.09254782,  0.15236378, -0.01034887, -0.27380484,\n",
      "       -0.40379834, -0.38791144,  0.04759864,  0.01187449,  0.28127757,\n",
      "       -0.5666141 , -0.07575742, -0.125983  ,  0.00626248, -0.02018097,\n",
      "        0.15199156, -0.08565389, -0.34658173, -0.07134286, -0.37585154,\n",
      "        0.2421458 ,  0.00526335,  0.10626591,  0.02215582,  0.33448085,\n",
      "       -0.40067437, -0.3634441 , -0.00449735, -0.08369254, -0.23804258,\n",
      "        0.02220448,  0.1931833 ,  0.0804124 , -0.09937143,  0.12598553,\n",
      "        0.32017398,  0.03649515, -0.11772335,  0.324128  , -0.2760405 ,\n",
      "       -0.18338431,  0.08443485,  0.20046642,  0.22800115,  0.20913598,\n",
      "       -0.12560141,  0.08714904, -0.02638753, -0.1352547 , -0.19359306,\n",
      "        0.39941087,  0.19930142,  0.31499225,  0.38807046,  0.33277327],\n",
      "      dtype=float32)\n",
      "'recognized'\n",
      "array([ 5.37565053e-02,  1.94320179e-04, -3.17516446e-01,  2.65351564e-01,\n",
      "        3.29832613e-01, -1.76504254e-01, -1.03110678e-01, -2.19100639e-02,\n",
      "        2.36013189e-01,  1.86339840e-01, -3.52284431e-01, -8.96139536e-03,\n",
      "       -3.70634407e-01,  2.25305185e-01,  1.53873220e-01, -3.38030308e-02,\n",
      "       -1.05008669e-01,  1.03509888e-01,  1.32527709e-01, -2.05579221e-01,\n",
      "       -1.32098615e-01,  1.51315749e-01, -2.06223011e-01,  1.45219695e-02,\n",
      "       -4.55963105e-01,  4.03399974e-01,  6.59888908e-02,  1.00204349e-01,\n",
      "        2.25826427e-01,  6.12930302e-03, -3.55781019e-01,  1.27924025e-01,\n",
      "        4.46887016e-02, -2.66243875e-01,  2.61073977e-01,  5.90505674e-02,\n",
      "       -8.69370773e-02, -3.52157503e-02,  2.29749367e-01,  1.17253236e-01,\n",
      "       -3.58435698e-03, -3.85273285e-02,  2.15277076e-01, -3.26565653e-02,\n",
      "        7.10259005e-02,  1.00325957e-01, -7.21117184e-02,  1.20601274e-01,\n",
      "       -8.43620114e-03, -2.13574409e-01, -3.14430058e-01, -3.03342134e-01,\n",
      "        3.58662941e-02,  8.51901621e-03,  2.20158234e-01, -4.40704405e-01,\n",
      "       -5.96965551e-02, -9.93348509e-02,  4.55718627e-03, -1.54262502e-02,\n",
      "        1.19393572e-01, -6.54367134e-02, -2.70891368e-01, -5.38915507e-02,\n",
      "       -2.92089522e-01,  1.88726813e-01,  4.40968014e-03,  8.48172233e-02,\n",
      "        1.80052202e-02,  2.60204285e-01, -3.12165022e-01, -2.81595916e-01,\n",
      "       -4.54013934e-03, -6.63988665e-02, -1.85677871e-01,  1.82009172e-02,\n",
      "        1.48100764e-01,  6.08697906e-02, -7.64838979e-02,  1.00731552e-01,\n",
      "        2.52339482e-01,  2.93226372e-02, -9.20657068e-02,  2.51948833e-01,\n",
      "       -2.15845466e-01, -1.41337752e-01,  6.53364435e-02,  1.55565798e-01,\n",
      "        1.76067889e-01,  1.61587656e-01, -9.58729982e-02,  6.79021701e-02,\n",
      "       -2.00029667e-02, -1.04311146e-01, -1.49983287e-01,  3.11795235e-01,\n",
      "        1.55156642e-01,  2.44292542e-01,  3.02202284e-01,  2.60028481e-01],\n",
      "      dtype=float32)\n",
      "'one'\n",
      "array([ 0.11273668,  0.00120545, -0.6808103 ,  0.57055235,  0.7053942 ,\n",
      "       -0.3715311 , -0.21860926, -0.05070821,  0.5007179 ,  0.39766935,\n",
      "       -0.7511897 , -0.01725577, -0.7957964 ,  0.47884935,  0.32733917,\n",
      "       -0.06874966, -0.22805497,  0.2203009 ,  0.28178748, -0.442203  ,\n",
      "       -0.27987975,  0.32266742, -0.44396988,  0.03136229, -0.971988  ,\n",
      "        0.85545594,  0.14130947,  0.21294372,  0.48201567,  0.0142934 ,\n",
      "       -0.7575793 ,  0.2706975 ,  0.09526741, -0.5662946 ,  0.5539485 ,\n",
      "        0.11971382, -0.18892491, -0.07773234,  0.49471688,  0.24854149,\n",
      "       -0.00821257, -0.0837471 ,  0.45535487, -0.07168569,  0.15174842,\n",
      "        0.21537456, -0.15444808,  0.25623497, -0.01882163, -0.45112976,\n",
      "       -0.67030483, -0.64608604,  0.07677837,  0.01684192,  0.47193244,\n",
      "       -0.94370776, -0.12923208, -0.20780577,  0.0110196 , -0.03838161,\n",
      "        0.25293016, -0.14153464, -0.57619   , -0.11930127, -0.6246556 ,\n",
      "        0.40767145,  0.00881167,  0.17798276,  0.03645829,  0.55942863,\n",
      "       -0.6689821 , -0.59862643, -0.00927912, -0.13685635, -0.39321184,\n",
      "        0.03908453,  0.31818748,  0.13437285, -0.16942582,  0.21312547,\n",
      "        0.53497726,  0.05875742, -0.19688495,  0.53537625, -0.45978504,\n",
      "       -0.30009264,  0.14534059,  0.3322771 ,  0.3785107 ,  0.34366226,\n",
      "       -0.20522918,  0.14312501, -0.03972465, -0.22005768, -0.32276395,\n",
      "        0.6667298 ,  0.3318035 ,  0.5169502 ,  0.64903355,  0.5540558 ],\n",
      "      dtype=float32)\n",
      "'top'\n",
      "array([ 0.07214109, -0.00241824, -0.43198034,  0.35463935,  0.44143716,\n",
      "       -0.23308392, -0.13816842, -0.03152069,  0.317736  ,  0.2478062 ,\n",
      "       -0.47370127, -0.01028231, -0.49725908,  0.3015986 ,  0.20278232,\n",
      "       -0.04212949, -0.14289273,  0.14016436,  0.17324091, -0.27590176,\n",
      "       -0.1813756 ,  0.2022755 , -0.2764161 ,  0.01933319, -0.61279404,\n",
      "        0.5409946 ,  0.08981604,  0.1306987 ,  0.3018765 ,  0.01063707,\n",
      "       -0.47569326,  0.1704627 ,  0.06073884, -0.3558784 ,  0.35035548,\n",
      "        0.07883875, -0.11993527, -0.05196342,  0.30910334,  0.1567506 ,\n",
      "       -0.00394644, -0.05069157,  0.29451394, -0.04338307,  0.09502997,\n",
      "        0.13975468, -0.10035137,  0.16177237, -0.00883003, -0.28478214,\n",
      "       -0.42110994, -0.40080574,  0.05204595,  0.01486555,  0.29435253,\n",
      "       -0.5919484 , -0.0787267 , -0.12871447,  0.00403811, -0.02441814,\n",
      "        0.1573722 , -0.08608647, -0.36031112, -0.07933794, -0.3920102 ,\n",
      "        0.2538908 ,  0.00307835,  0.11318307,  0.01887384,  0.34931332,\n",
      "       -0.41804144, -0.37932062, -0.00745618, -0.09222978, -0.25022098,\n",
      "        0.02104878,  0.19974598,  0.0842865 , -0.10685379,  0.13308118,\n",
      "        0.33741376,  0.04060272, -0.12593812,  0.33721974, -0.28575844,\n",
      "       -0.19170968,  0.08719172,  0.21469097,  0.23819426,  0.21479085,\n",
      "       -0.12910773,  0.09333458, -0.02758101, -0.13909224, -0.20293726,\n",
      "        0.42102858,  0.2082135 ,  0.32872605,  0.40772527,  0.35048708],\n",
      "      dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swapnil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for ind in df.index:\n",
    "    if ind < 1:\n",
    "        #create a vector sentence to hold headlines\n",
    "        sentence = df['SENTENCES'][ind]        \n",
    "        #tokenize the headline\n",
    "        text = [word.lower() for word in sentence.split()]\n",
    "        #print(text)\n",
    "        \n",
    "        #process the headline, after this headlines will be ready for calculate embeddings\n",
    "        processed_text = remove_stopwords(text, stop_words)\n",
    "        print(str(processed_text) + '\\n')\n",
    "        \n",
    "        #obtain word_embeddings for each word in headline and divide their sum by len(processed_text)\n",
    "        vectorized_text = create_word_embeddings(model, processed_text)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
